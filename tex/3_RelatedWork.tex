%%%%%%%%%%%%%% REFRASEAR (CTRL C + CTRL V) %%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%
% verification
%%%%%%%%%%%%%%


% Formal Verification of Cyber-Physical Systems: Coping with Continuous Elements
% Given the extensive usage of CPS in safety-critical applications, there is a dire need of using formal methods for their analysis. However, the frequent involvement of ordinary differential equations (ODEs) in their analysis is a main limiting factor in this direction. For example, ODEs are essential for modeling the motion of mechanical parts, analog circuits and control systems, which are some of the most common elements of any CPS. Thus, automatic state-based formal methods, like model checking, and automatic theorem provers cannot be used to model and analyze the true CPS models due to their inability to model continuous systems. 

% checkout the related work section from An Improved Negative Selection Algorithm-Based Fault Detection Method


% Comparative Analysis of Statistical Model Checking Tools
% To overcome the state-space explosion problem, the statistical model checking (SMC) approach does not analyse the entire state space, but instead generates a number of independent simulation traces and uses statistical (e.g., Monte Carlo) methods to generate an approximate measure of system correctness. This approach does not guarantee the absolute correctness of the system, but it allows much larger models be verified (within specified confidence limits) in a faster manner [12, 37, 49, 51]. 

%%%%%%%%%%%%%%%%%%%%%%% FIM REFRASEAR %%%%%%%%%%%%%%%%%%%%%


This chapter discusses relevant work related to the themes discussed in this document. The first one is related to verification methods in Cyber-Physical Systems. The second topic deals with the usage of the Negative Selection Algorithm in fault diagnosis of CPSs.

%%%%%%%%%%%%%%%%%%%%%%%
\section{Verification Methods in Cyber-Physical Systems}
%%%%%%%%%%%%%%%%%%%%%%%

Formal Methods are widely applied the analysis of CPS because of their expanding application in many safety and financial-critical sectors. Model Checking, for example, is particularly popular since it addresses multiple aspects found in CPSs \cite{2014PerceptionsSOTAV&VCPS}.

% areas in which model checking is applied for verification

Nevertheless, the complexity found in CPSs can bring problems to the design of such systems. 
Representing both the cyber and physical aspects of any CPS challenges the task of modeling such systems, since we are combining discrete and continuous models. Aside from the complexity of representing the real environment, a CPS has only a limited understanding of its surroundings. Sensing constraints induced by sensor blindspots and sensor interference complicate the modeling process \cite{luckcuck2019formal}. Hence, oversimplified models may be invalidated for not anticipating failures dependant on the two layers \cite{2014PerceptionsSOTAV&VCPS}. 

Akella et al. \cite{akella2009model}, for instance, addresses this problem by trying to simplify the physical model. This was done by discretizing the events that cause flow change and to representing the CPS as a deterministic state model with discrete flow values inside its physical components. Model checking is then utilized to formally test insecure interactions between all conceivable behaviors of the specified CPS. Botaschanjan et al. \cite{botaschanjan2008correctness} provide a sucessfull attempt to close this gap in automotive systems by combining the model checking verification of the lower layers of the system with the simulation of the upper layers.

Formal methods can also be used to perform anomaly detection. Jones et al. \cite{jones2014anomaly} uses formal methods to an anomaly detection framework to determine whether or not a particular CPS is under attack. They build STL properties based on the normal behavior of the system and flag the abnormal behavior. Then, a one-class SVM model is used to detect deviations. Our approach share some similarities with Jone's. Nonself data, i.e. anomalies, are flagged according to system properties and a one-class machine learning algorithm (NSA) is performed to understand the patterns based on the self data. Although in our work the properties are specified by the stakeholders and undergo a process of formalism. Besides that, we leverage the detectors generated to gain insight on the violations, which is used to enhance the specification. Webster \cite{webster2014generating} also integrates model checking and simulation in order to ensure safe operations for autonomous unmanned aircrafts. They argue that the high level of assurance provided by the formal method would increase the accuracy of the simulation model.

% Clarke and Zuliani suggested a Statistical Model Checking \cite{clarke2011statistical}, which relies on statistical analysis to prune the verification. Nevertheless, it still suffers from the main problems of the Model Checking approach, such as 



% (REPHRASE) CPS exhibits bugs that crop up only at run-time based on the physical state of the deployment world; such bugs cannot be captured by model checking alone -> THUS RUNTIME VERIFICATION

Another issue with model checking is that some of the system properties of the CPSs may not be thoroughly verified and tested during the design and building phases. An alternative is performing the verification task after the system is deployed, in what is called Runtime Verification. This technique is considered to be a lightweight dynamic formal method in the sense that it is performed during the CPS's execution and relies on the verification of real data for the assurance of safety properties \cite{colombo2021runtime}. One of the ways in which it can be realized is by using Observers, which are a reification of the property in the form of state machines. They are responsible for reading the signals and messages that are shared among the modules of the system, checking the system's logs and so on, in order to perform statistics, identify faults and so on. They can be derived from the specified system properties through pattern catalogs \cite{2022PSP}.

In the proposed framework, the model checking process will be integrated with simulation. This will be done by implementing a prototype in Modelica \cite{Modelica}, which is a tool that allows for writing algorithms and physical equations, for the modeling of the cyber and physical aspects of the system. Observers will also be modeled as timed automata for the model checking phase, as well as implemented as components in the prototype. This will allow for a seamless transition from runtime and design time.

% [2014]  Generating Certification Evidence for Autonomous Unmanned Aircraft Using Model Checking and Simulation

% cite [2017] Combining Model Checking and Runtime Verification for safe robotics

%  cite seams 18


% Nevertheless, the complexity found in CPSs can bring problems to the design of such systems. 
% In large-scale environments, there are typically a variety of objectives to be met, a broad range of physical components to manage and coordinate, a number of different sensors, and actuators. 
% Additionally, environmental factors are not predicted with absolute certainty, and each physical components is susceptible to failure \cite{jacoby2010testing}. 
% Besides that, the complexities of representing both the cyber and physical aspects of any CPS challenges the task of modeling such systems. Oversimplified models may be invalidated for not anticipating failures dependant on the two layers \cite{2014PerceptionsSOTAV&VCPS}. 


\section{Fault Analysis and the Negative Selection}

Another method for increasing the reliability of CPSs is fault detection, diagnosis and isolation (FDDI), which is conceptually similar to the assessment of property violations. Both are looking for techniques to determine whether and why the system is not operating as planned. In this sense, understanding which approaches are being utilized in the FDDI field may help us to better evaluate our methodology.

Zhang et al. \cite{zhang2013sensor} suggests a model-based detection, isolation, and system reconfiguration techinque for induction motor drives dependant on extended EKF, as well as strong current and DC-link voltage observers, which allows the systems to continue its operation even under sensor faults. Poon et al. \cite{poon2016model} also relies on models to present a fault detection and identification (FDI) technique for switching power converters utilizing a model-based state estimator methodology, which boosts fault tolerance and awareness in power electronics systems. Garcia et al. \cite{garcia2022solar} provides a real-time monitoring and preventive fault diagnosis method for solar panel strings in real-world installations, through the identification and parametric separation of fault symptoms using Voc-Isc curve analysis. In this strategy, identification and isolation occur with sufficient leeway to notify and stop the deterioration phenomena and its cumulative impact, which would potentialy result in the formation of irreversible failure via automated disconnection.

However, the success of traditional fault detection systems is determined by a number of elements, including prior knowledge of defective responses, an accurate system model, and a vast amount of data-history patterns. Furthermore, typical fault detection algorithms are often developed for a single system, thereby addressing a restricted number of defect types \cite{abid2020improved}.

These limitations motivated the adoption of new approaches, which make use of machine learning techniques. Chopdar and Koshti \cite{9848016}, for instance, address the problem of faults in the growing number of power grid transmission lines via an Artificial Neural Network method that efficiently detects and classifies faults to keep the performance of the power system. The model was trained with data taken from simulation software, which reduced the demand for historical data.
% Get another example that addresses the problems listed

Nevertheless, there is still a critical necessity for the development of efficient fault detection systems that are less domain-specific. In this sense, Artificial immune systems (AIS) have recently captured the interest of the scientific community, specially for the purpose of anomaly detection. The Negative Selection Algorithm (NSA), which is inspired by the self/nonself discrimination process performed by the body during an immune response \cite{Kuby2019}, has emerged as a viable alternative \cite{abid2020improved}.

Gupta and Dasgupta \cite{NSAResearch2021} provide a detailed assessment of the literature, demonstrating how the approach has evolved through time, highlighting the most notable variations and comparing with similar alternatives. They come to the conclusion that NSA outperforms most other approaches for nonlinear representation, and it can perform better than neural-based models in computing time.  

Govender and Mensah \cite{govender2010fault} propose the usage of the NSA in modern manufacturing settings, in order to minimize the production lossess related to equipment malfuctioning. They simulate an automobile hub pressing machine using Matlab that has a programmable logic controller (PLC) connected to sensors, switches and safety curtains, and a module hosting the AIS. The self-set training data comes from the execution of the system under error free operations and are represented in the Hamming space as binary strings. Nonself detectors are randomly generated in the censoring phase of the algorithm by using the Hamming distance for the comparisons. Finally, the detectors are used in runtime to determine the anomalies in a hierachical fashion. They state that the representation of the data as binary strings allow for the reverse map of the resulting detectors back into the real nature of the equipment, even though the paper does not further explore this aspect.

Our approach makes use of the NSA in a similar way. The Hamming space is leveraged as a means to reverse map the detectors into system states during the pattern analysis process. However, we consider this idea paramount for the increase of the reliability of CPSs, since the explainability it provides enables the identification of design failures, the creation of fault tolerant mechanisms and the refinement of the system properties.

Two other works are worth mentioning in this section. The first, Alizadeh et al. \cite{alizadeh2016negative} suggested a wind turbine defect diagnostic system that relies on real-valued NSA to boost nonself-space coverage. V-detectors are used for representing the detectors, the Euclidean distance is utilized for matching, and data are represented as spheres. The detection phase proceeds as default, but the isolation phase relies on the training of new instances of the NSA for each pre-defined fault, which are employed in a hierarchical manner to better describe identified faults. The second was proposed by Ren et al. \cite{ren2020novel} a different algorithm for fault discovery and isolation. In this paper, V-detectors are created in such a way that the detector's coverage is increased while the overlap is reduced. The detection phase contains no surprises, but the isolation phase relies on an algorithm that attempts to match the defect at hand with a collection of pre-identified fault representatives.

Both frameworks use more advanced Negative Selection algorithms, that rely on real-valued data representation, while our approach still represents the data as binary strings. Nevertheless, even with the well-knwon shortcommings of the binary NSA, the explainability provided by the detectors eliminates the need for any prior knowledge of the system's probable faults.

\section{Final Considerations on Related Works}

Our work lies in the line that unites design time and runtime. we aim at enhancing the CPSs reliability by improving the process of specification of system properties. In that sense, a model checking process is performed based on a timed-automata model of the system and a set of system properties derived from the specification. To account for the complexities found in the relation between computing and physical process \cite{2014PerceptionsSOTAV&VCPS}, a prototype of the system will be implemented in a tool designed to simulate Cyber-physical Systems, named Modelica. It provides both a cyber and a model interface, which allows for the simulation of physical equations integrated with algorithms \cite{fritzson2011introduction}. 

Additionally, observer automata will be derived from the properties and implemented in the prototype. This will enable the usage of runtime verification techniques while still in design time. A dataset will be extracted from simulation containing the execution logs, which will then be used in the Negative Selection Algorithm \cite{NSAResearch2021} for the discovery of patterns that are related to the violation of the specified properties. The patterns will be analyzed and used to enhance the properties, the system specification itself and make room for the development of fault-tolerant mechanisms and runtime monitors. We believe that these measures will account for the enhancing of the overall reliability of the system.
